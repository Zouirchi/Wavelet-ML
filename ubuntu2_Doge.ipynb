{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1f48700-0775-4931-a49d-5caaf2176738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1546\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028   \n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023   \n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016   \n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016  \n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012   \n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013  \n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016  \n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012   \n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018\n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021  \n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014   \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012   \n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013   \n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016   \n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017   \n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029\n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025\n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012   \n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "Prochaine valeur prédite pour cD1 : 0.0012739909579977393\n",
      "Le signal devrait augmenter.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1733\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027    \n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022    \n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024    \n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026    \n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027    \n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020    \n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "Prochaine valeur prédite pour cD2 : -8.548980258638039e-05\n",
      "Le signal devrait augmenter.\n",
      "Achetez\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "#data = data[:-1] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86cd5c5b-16df-4972-9013-edb26e6bfffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1011\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014  \n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011    \n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014  \n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019   \n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016   \n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017   \n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018\n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015\n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014   \n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021   \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017   \n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026\n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021  \n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015   \n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012    \n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6937e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021  \n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "Prochaine valeur prédite pour cD1 : -0.0002458002418279648\n",
      "Le signal devrait diminuer.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0878\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018    \n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018    \n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022    \n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028    \n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0043\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029    \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "Prochaine valeur prédite pour cD2 : -0.0004073911113664508\n",
      "Le signal devrait augmenter.\n",
      "N'achetez pas\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "data = data[:-1] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "257dc842-7c4c-4ae9-9ab3-9771578913c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0826\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012   \n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017  \n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011    \n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 \n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016  \n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011    \n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012   \n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012   \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6779e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025  \n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021\n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012  \n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019  \n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018\n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023\n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "Prochaine valeur prédite pour cD1 : 0.0011776001192629337\n",
      "Le signal devrait diminuer.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0794\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0046\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0039\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024    \n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031  \n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0023\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029  \n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0032\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "Prochaine valeur prédite pour cD2 : -0.0010233873035758734\n",
      "Le signal devrait diminuer.\n",
      "N'achetez pas\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "data = data[:-2] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b8de9cc-cceb-4762-a244-f897f44c4f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1100\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013  \n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021\n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013   \n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013   \n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025\n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015  \n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8726e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 \n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014  \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019\n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022\n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017   \n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018  \n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019\n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017   \n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018   \n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Prochaine valeur prédite pour cD1 : 0.00011438730143709108\n",
      "Le signal devrait augmenter.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1209\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023   \n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0050\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018   \n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013   \n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032   \n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022   \n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "Prochaine valeur prédite pour cD2 : -0.0023818030022084713\n",
      "Le signal devrait diminuer.\n",
      "N'achetez pas\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "data = data[:-3] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5da975a-de34-4dec-b3fd-e8349824f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0985\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012  \n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014\n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016  \n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 \n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012  \n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 \n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019  \n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 \n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022  \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017\n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019\n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 \n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018\n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018\n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013   \n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014  \n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "Prochaine valeur prédite pour cD1 : 0.0007759393774904311\n",
      "Le signal devrait augmenter.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1136\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0129\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022    \n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020   \n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031    \n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023   \n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032     \n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "Prochaine valeur prédite pour cD2 : -0.0017966266022995114\n",
      "Le signal devrait diminuer.\n",
      "N'achetez pas\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "data = data[:-4] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "272d92da-08b8-4cd3-9f79-d74717c37af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0987\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014  \n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012   \n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 \n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016  \n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 \n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017\n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 \n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4983e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013   \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011\n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 \n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017\n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020\n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 \n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016\n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step\n",
      "Prochaine valeur prédite pour cD1 : 0.0014956570230424404\n",
      "Le signal devrait augmenter.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1231\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0092\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025  \n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015  \n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0031\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025  \n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020    \n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0026\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027    \n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026   \n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016    \n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "Prochaine valeur prédite pour cD2 : -0.002034673700109124\n",
      "Le signal devrait diminuer.\n",
      "N'achetez pas\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "data = data[:-5] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22d8c85a-18fc-44ab-b512-6d8776dca62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0641\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016\n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012   \n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 \n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017\n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017   \n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019  \n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022\n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015  \n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012   \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6707e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016  \n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015\n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019\n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 \n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010    \n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019  \n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "Prochaine valeur prédite pour cD1 : 0.0019305325113236904\n",
      "Le signal devrait augmenter.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1823\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023   \n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027   \n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019   \n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016   \n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022   \n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025    \n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024   \n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029   \n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017   \n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029    \n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
      "Prochaine valeur prédite pour cD2 : -0.0006425349856726825\n",
      "Le signal devrait augmenter.\n",
      "Achetez\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "data = data[:-6] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fcfb973-88c5-4308-8e23-9211d8351948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0775\n",
      "Epoch 2/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032\n",
      "Epoch 3/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017  \n",
      "Epoch 4/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020  \n",
      "Epoch 5/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028\n",
      "Epoch 6/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016\n",
      "Epoch 7/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014  \n",
      "Epoch 8/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018  \n",
      "Epoch 9/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017  \n",
      "Epoch 10/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014  \n",
      "Epoch 11/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014  \n",
      "Epoch 12/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015  \n",
      "Epoch 13/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018\n",
      "Epoch 14/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015  \n",
      "Epoch 15/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034\n",
      "Epoch 16/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016  \n",
      "Epoch 17/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1774e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017  \n",
      "Epoch 19/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025\n",
      "Epoch 20/20\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "Prochaine valeur prédite pour cD1 : 0.0019387624925002456\n",
      "Le signal devrait augmenter.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/Desktop/qiskit-env/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2017\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0074\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031    \n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018    \n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019   \n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028   \n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021   \n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0020\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023    \n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017   \n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "Prochaine valeur prédite pour cD2 : -0.0017094237264245749\n",
      "Le signal devrait augmenter.\n",
      "Achetez\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "file_path = '/home/ab/Desktop/MASTER DSEF/Dogecoin Historical Data_.ods'\n",
    "db = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir la colonne 'Date' en format datetime en utilisant le format correct\n",
    "db['Date'] = pd.to_datetime(db['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Inverser l'ordre des données (de la plus ancienne à la plus récente)\n",
    "data = db.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "data = data[:-7] # sup\n",
    "\n",
    "date_column = 'Date'\n",
    "close_column = 'Price'\n",
    "\n",
    "dates = pd.to_datetime(data[date_column])\n",
    "close_prices = data[close_column]\n",
    "\n",
    "# Décomposition en ondelettes\n",
    "coeffs = pywt.wavedec(close_prices, 'db4', level=2)\n",
    "cA2, cD2, cD1 = coeffs\n",
    "\n",
    "approximation = pywt.upcoef('a', cA2, 'db4', level=2, take=len(close_prices))\n",
    "detail2 = pywt.upcoef('d', cD2, 'db4', level=2, take=len(close_prices))\n",
    "detail1 = pywt.upcoef('d', cD1, 'db4', level=1, take=len(close_prices))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD1_scaled = scaler.fit_transform(cD1.reshape(-1, 1))\n",
    "\n",
    "# Création des fenêtres temporelles\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD1_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD1)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD1 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD1 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD1 = scaler.inverse_transform(predicted_value_cD1)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD1 : {predicted_value_rescaled_cD1[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cA1\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD1 > last_cD1_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Normalisation des données pour cD2\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "cD2_scaled = scaler.fit_transform(cD2.reshape(-1, 1))  # Remplacez cD2 par vos données de cD2\n",
    "\n",
    "# Création des fenêtres temporelles pour cD2\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size, 0])  # Séquence des données passées\n",
    "        y.append(data[i+window_size, 0])  # Prochaine valeur (target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 10  # Utilisez les 10 dernières valeurs pour prédire la suivante\n",
    "X, y = create_dataset(cD2_scaled, window_size)\n",
    "\n",
    "# Reshape des données pour LSTM [échantillons, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Définition du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))  # Une seule sortie (la prochaine valeur de cD2)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
    "\n",
    "# Prédire la prochaine valeur de cD2 à partir de la dernière fenêtre de test\n",
    "predicted_value_cD2 = model.predict(X_test[-1].reshape(1, window_size, 1))\n",
    "\n",
    "# Inverse de la normalisation pour obtenir la valeur réelle\n",
    "predicted_value_rescaled_cD2 = scaler.inverse_transform(predicted_value_cD2)\n",
    "\n",
    "# Affichage de la valeur prédite\n",
    "print(f\"Prochaine valeur prédite pour cD2 : {predicted_value_rescaled_cD2[0][0]}\")\n",
    "\n",
    "# Dernière valeur de cA1 (approximation à un certain niveau)\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "\n",
    "# Valeur prédite rééchelonnée (prédiction pour le prochain point)\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2[0][0]\n",
    "\n",
    "# Comparaison entre la dernière valeur de cA1 et la valeur prédite\n",
    "if predicted_value_rescaled_cD2 > last_cD2_value:\n",
    "    print(\"Le signal devrait augmenter.\")\n",
    "else:\n",
    "    print(\"Le signal devrait diminuer.\")\n",
    "\n",
    "# Définir les valeurs à comparer\n",
    "last_cD2_value = cD2[-1]  # Dernière valeur de cD2\n",
    "last_cD1_value = cD1[-1]  # Dernière valeur de cD1\n",
    "predicted_value_rescaled_cD1 = predicted_value_rescaled_cD1  # Prédiction pour cD1\n",
    "predicted_value_rescaled_cD2 = predicted_value_rescaled_cD2  # Prédiction pour cD2\n",
    "\n",
    "# Condition pour Achat, Vente ou Neutre\n",
    "if last_cD2_value < predicted_value_rescaled_cD2 and last_cD1_value < predicted_value_rescaled_cD1:\n",
    "    print(\"Achetez\")\n",
    "elif last_cD2_value >= predicted_value_rescaled_cD2 and last_cD1_value >= predicted_value_rescaled_cD2:\n",
    "    print(\"N'achetez pas\") # vente\n",
    "else:\n",
    "    print(\"N'achetez pas\") # neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba908c-e540-4b34-ab5d-0b3901811f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3dd02e-01df-4521-8535-c950f5245ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d30e30-058d-4f23-916f-693073fc5f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eefa4b-9eda-46c1-b658-1b9da98f8e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc23a5-0d3a-43bf-b569-a60f3e39140c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
